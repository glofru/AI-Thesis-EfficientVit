{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8823fec6-8ba0-493b-bd48-c4225db4f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as TT\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2efe88f5-a52f-4f61-9791-8cadb2dc3a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"seed\": 4242,\n",
    "    \"img_res\": (3, 256, 256),\n",
    "    \"depth_img_res\": (1, 64, 64),\n",
    "    \"n_workers\": 2,\n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"batch_size_eval\": 1,\n",
    "    \"lr\": 1e-3,\n",
    "    \"lr_patience\": 15,\n",
    "    \"e_stop_epochs\": 30,\n",
    "    \"epochs\": 120,\n",
    "}\n",
    "\n",
    "dataset_root = './data/NYUv2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79076b-26fa-432f-a6a2-b74f062d29a1",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96cb6c64-e16d-40b3-bb90-3ac7741f3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardware_check(gpu=False):\n",
    "    if gpu:\n",
    "        if not torch.cuda.is_available():\n",
    "            raise \"GPU not present\"\n",
    "        return \"cuda:0\"\n",
    "    return \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcd3f1-5a39-4f95-88ac-e6b79b2a1007",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e81154c-caec-4a36-b21c-58f2402e71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYU2_Dataset:\n",
    "    \"\"\"\n",
    "      * Indoor img (480, 640, 3) depth (480, 640, 1) both in png -> range between 0.5 to 10 meters\n",
    "      * 654 Test and 50688 Train images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, dts_type, aug, rgb_h_res, d_h_res, dts_size=0, scenarios='indoor'):\n",
    "        self.dataset = path\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.info = 0\n",
    "        self.dts_type = dts_type\n",
    "        self.aug = aug\n",
    "        self.rgb_h_res = rgb_h_res\n",
    "        self.d_h_res = d_h_res\n",
    "        self.scenarios = scenarios\n",
    "\n",
    "        # Handle dataset\n",
    "        if self.dts_type == 'test':\n",
    "            img_path = self.dataset + self.dts_type + '/eigen_test_rgb.npy' # '/content/drive/MyDerive/....FOLDER X .../test/carica_file_test.npy\n",
    "            depth_path = self.dataset + self.dts_type + '/eigen_test_depth.npy'\n",
    "\n",
    "            rgb = np.load(img_path)\n",
    "            depth = np.load(depth_path)\n",
    "\n",
    "            self.x = rgb\n",
    "            self.y = depth\n",
    "\n",
    "            if dts_size != 0:\n",
    "                self.x = rgb[:dts_size]\n",
    "                self.y = depth[:dts_size]\n",
    "\n",
    "            self.info = len(self.x)\n",
    "\n",
    "        elif self.dts_type == 'train':\n",
    "            scenarios = os.listdir(self.dataset + self.dts_type + '/')\n",
    "            for scene in scenarios:\n",
    "                elem = os.listdir(self.dataset + self.dts_type + '/' + scene)\n",
    "                for el in elem:\n",
    "                    if 'jpg' in el:\n",
    "                        self.x.append(self.dts_type + '/' + scene + '/' + el)\n",
    "                    elif 'png' in el:\n",
    "                        self.y.append(self.dts_type + '/' + scene + '/' + el)\n",
    "                    else:\n",
    "                        raise SystemError('Type image error (train)')\n",
    "\n",
    "            if len(self.x) != len(self.y):\n",
    "                raise SystemError('Problem with Img and Gt, no same train_size')\n",
    "\n",
    "            self.x.sort()\n",
    "            self.y.sort()\n",
    "\n",
    "            if dts_size != 0:\n",
    "                self.x = self.x[:dts_size]\n",
    "                self.y = self.y[:dts_size]\n",
    "\n",
    "            self.info = len(self.x)\n",
    "\n",
    "        else:\n",
    "            raise SystemError('Problem in the path')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.info\n",
    "\n",
    "    def __getitem__(self, index=None, print_info_aug=False):\n",
    "        if index is None:\n",
    "            index = np.random.randint(0, self.info)\n",
    "\n",
    "        # Load Image\n",
    "        if self.dts_type == 'test':\n",
    "            img = self.x[index]\n",
    "        else:\n",
    "            img_name = self.dataset + self.x[index]\n",
    "            try:\n",
    "                raw_img = Image.open(img_name)\n",
    "                img = np.array(raw_img.convert('RGB'))\n",
    "                raw_img.close()\n",
    "            except:\n",
    "                exit(f\"Failed opening {img_name}\")\n",
    "\n",
    "        # Load Depth Image\n",
    "        if self.dts_type == 'test':\n",
    "            depth = np.expand_dims(self.y[index] * 100, axis=-1)\n",
    "        else:\n",
    "            depth = Image.open(self.dataset + self.y[index])\n",
    "            depth = np.array(depth) / 255\n",
    "            depth = np.clip(depth * 1000, 50, 1000)\n",
    "            depth = np.expand_dims(depth, axis=-1)\n",
    "\n",
    "        # Augmentation\n",
    "        if self.aug:\n",
    "            img, depth = augmentation2D(img, depth, print_info_aug)\n",
    "\n",
    "        img_post_processing = TT.Compose([\n",
    "            TT.ToTensor(),\n",
    "            TT.Resize((param['img_res'][1], param['img_res'][2]), antialias=True),\n",
    "            TT.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Imagenet\n",
    "        ])\n",
    "        depth_post_processing = TT.Compose([\n",
    "            TT.ToTensor(),\n",
    "            TT.Resize((param['depth_img_res'][1], param['depth_img_res'][2]), antialias=True),\n",
    "        ])\n",
    "\n",
    "        img = img_post_processing(img/255)\n",
    "        depth = depth_post_processing(depth)\n",
    "\n",
    "        return img.float(), depth.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa2ddb0-ecb7-4b53-a392-a37e216dc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_test_loader(dts_root_path, rgb_h_res, d_h_res, bs_train, bs_eval, num_workers, size_train=0, size_test=0):\n",
    "    # Load Datasets\n",
    "    test_Dataset = NYU2_Dataset(\n",
    "        path=dts_root_path, dts_type='test', aug=False, rgb_h_res=rgb_h_res, d_h_res=d_h_res, dts_size=size_test\n",
    "    )\n",
    "    training_Dataset = NYU2_Dataset(\n",
    "        path=dts_root_path, dts_type='train', aug=True, rgb_h_res=rgb_h_res, d_h_res=d_h_res, dts_size=size_train\n",
    "    )\n",
    "    # Create Dataloaders\n",
    "    training_DataLoader = DataLoader(\n",
    "        training_Dataset, batch_size=bs_train, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    test_DataLoader = DataLoader(\n",
    "        test_Dataset, batch_size=bs_eval, shuffle=False, num_workers=num_workers, pin_memory=True\n",
    "    )\n",
    "\n",
    "    return training_DataLoader, test_DataLoader, training_Dataset, test_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d4b8a-782c-47d8-b70b-5fbe4367950f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042bf629-d738-4df0-b390-c86fedfedf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evaluation(test_dataloader, model, name, gpu=False):\n",
    "    times = np.zeros(len(test_dataloader))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, depths) in enumerate(test_dataloader):\n",
    "        if gpu:\n",
    "            inputs, depths = inputs.cuda(), depths.cuda()\n",
    "        else:\n",
    "            inputs, depths = inputs.cpu(), depths.cpu()\n",
    "\n",
    "        start = time.time()\n",
    "        with torch.no_grad():\n",
    "            predictions = model(inputs)\n",
    "        end = time.time()\n",
    "\n",
    "        total = end - start\n",
    "        times[i] = total\n",
    "\n",
    "    average = np.average(times)\n",
    "    median = np.percentile(times, 50)\n",
    "    p90 = np.percentile(times, 90)\n",
    "\n",
    "    return [name, gpu, average, median, p90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ff7978-844b-48e0-8d61-5da497cdcb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654 samples\n"
     ]
    }
   ],
   "source": [
    "_, test_dataloader, __, ___ = init_train_test_loader(\n",
    "    dts_root_path=dataset_root,\n",
    "    rgb_h_res=param['img_res'][1],\n",
    "    d_h_res=param['depth_img_res'][1],\n",
    "    bs_train=param['batch_size'],\n",
    "    bs_eval=param['batch_size_eval'],\n",
    "    num_workers=param['n_workers'],\n",
    ")\n",
    "\n",
    "print(f\"{len(test_dataloader)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e264602-996d-4803-b02b-dd2611005491",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['name', 'gpu', 'average', 'median', 'p90'])\n",
    "\n",
    "index = 0\n",
    "def evaluate_model(build_model, gpu, test_name, device, arch_type=None):\n",
    "    global index\n",
    "    \n",
    "    if arch_type:\n",
    "        model = build_model(device=device, arch_type='s').to(device=device)\n",
    "    else:\n",
    "        model = build_model(device=device).to(device=device)\n",
    "    \n",
    "    evaluation = compute_evaluation(test_dataloader, model, test_name, gpu)\n",
    "    results.loc[index] = evaluation\n",
    "    index += 1\n",
    "\n",
    "for gpu in [True, False]:\n",
    "    device = hardware_check(gpu)\n",
    "\n",
    "    # Training notebooks have been exported into Python scripts to make the import works\n",
    "    from original import build_model\n",
    "    evaluate_model(build_model, gpu, \"METER original\", device, 's')\n",
    "\n",
    "    from efficient_vit import build_model\n",
    "    evaluate_model(build_model, gpu, \"EfficientVit\", device)\n",
    "\n",
    "    from mob_eff import build_model\n",
    "    evaluate_model(build_model, gpu, \"Mobile + EfficientVitBlock\", device)\n",
    "\n",
    "    from meta_meter import build_model\n",
    "    evaluate_model(build_model, gpu, \"Meta METER\", device)\n",
    "\n",
    "    from meta_eff import build_model\n",
    "    evaluate_model(build_model, gpu, \"Meta EfficientVit\", device)\n",
    "\n",
    "results.to_csv(\"results_time.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2e25d-241d-4c91-b05c-008db6a6a8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
